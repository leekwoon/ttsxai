{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import torch\n",
    "\n",
    "import neurox.interpretation.utils as utils\n",
    "import neurox.interpretation.ablation as ablation\n",
    "import neurox.interpretation.linear_probe as linear_probe\n",
    "\n",
    "from ttsxai.utils.utils import read_ljs_metadata\n",
    "\n",
    "\n",
    "log_dir = '/nas/users/dahye/kw/tts/ttsxai/logs/probe_tacotron2_articulatory_features'\n",
    "data_activation_dir = \"/nas/users/dahye/kw/tts/ttsxai/data_activation/LJSpeech/tacotron2_waveglow\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = np.load(os.path.join(log_dir, 'data', 'train_data.npz'), allow_pickle=True)\n",
    "X = data_dict['X']\n",
    "y = data_dict['y']\n",
    "label2idx = data_dict['label2idx'].item()\n",
    "idx2label = data_dict['idx2label'].item()\n",
    "src2idx = data_dict['src2idx'].item()\n",
    "idx2src = data_dict['idx2src'].item()\n",
    "neuronidx2name = data_dict['neuronidx2name'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification probe\n",
      "Creating model...\n",
      "Number of training instances: 859266\n",
      "Number of classes: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pre-trained probe\n",
    "probe = linear_probe.train_logistic_regression_probe(\n",
    "    X, y, lambda_l1=0.001, lambda_l2=0.001,\n",
    "    num_epochs=0)\n",
    "probe.load_state_dict(\n",
    "    torch.load(os.path.join(log_dir, 'models', 'probe.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80c3ba8a0e048e89d0d9692be804f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ordering, cutoffs = linear_probe.get_neuron_ordering(probe, label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bilabial': 0,\n",
       " 'Glottal': 1,\n",
       " 'Labio-Velar': 2,\n",
       " 'Dental': 3,\n",
       " 'Velar': 4,\n",
       " 'Vowel': 5,\n",
       " 'Alveolar': 6,\n",
       " 'Labiodental': 7,\n",
       " 'Palatal': 8,\n",
       " 'Post-Alveolar': 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1186, 1158, 1678, 1166, 1459, 1235, 1142, 1240, 1531, 1340])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ordering[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bilabial [1531 1236 1347 1427 1353 1222 1035 1029 1472 1525]\n",
      "Glottal [1459 1033 1188 1445 1270 1421 1183 1226 1480 1489]\n",
      "Labio-Velar [1340 1207 1145 1440 1077 1159 1257 1526 1477 1308]\n",
      "Dental [1166 1116 1322 1389 1484 1227 1711 1645   81  737]\n",
      "Velar [1240 1024 1412 1426 1280 1330 1037 1385 1364 1043]\n",
      "Vowel [1678 1681 1710 1605 2031 1608 1567 1722 1517 1733]\n",
      "Alveolar [1235 1517 1424 1300 2043 1204 1176 1290 1605 1651]\n",
      "Labiodental [1158 1283 1358 1428 1268 1309 1472 1369 1075 1467]\n",
      "Palatal [1142 1110 1521 1042 1355 1122 1511 1429 1281 1115]\n",
      "Post-Alveolar [1186 1342 1495 1493 1075 1417 1138 1031 1089 1444]\n"
     ]
    }
   ],
   "source": [
    "for k in label2idx.keys():    \n",
    "    best_10 = get_neuron_ordering_for_class(probe, k, label2idx)[:10]\n",
    "    print(k, best_10)\n",
    "    # print([neuronidx2name[i] for i in best_10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1531, 1236, 1347, ..., 1314,  551, 1740])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_neuron_ordering_for_class(probe, 'Bilabial', label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neuron_ordering_for_class(probe, class_name, class_to_idx, search_stride=100):\n",
    "    \"\"\"\n",
    "    Get neuron ordering for a specific class from a trained probe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    probe : interpretation.linear_probe.LinearProbe\n",
    "        Trained probe model\n",
    "    class_name : str\n",
    "        The name of the class for which to find the neuron ordering\n",
    "    class_to_idx : dict\n",
    "        Class to class index mapping\n",
    "    search_stride : int, optional\n",
    "        Number of steps to divide the weight mass percentage\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    neuron_ordering : numpy.ndarray\n",
    "        Array of neurons ordered by their importance for the specified class\n",
    "    \"\"\"\n",
    "    class_idx = class_to_idx[class_name]\n",
    "    weights = list(probe.parameters())[0].data.cpu().numpy()\n",
    "    abs_weights = np.abs(weights[class_idx])\n",
    "\n",
    "    neuron_orderings = []\n",
    "    for p in range(1, search_stride + 1):\n",
    "        percentage = p / search_stride\n",
    "        total_mass = np.sum(abs_weights)\n",
    "        sorted_idx = np.argsort(abs_weights)[::-1]  # Sort in descending order\n",
    "        cum_sums = np.cumsum(abs_weights[sorted_idx])\n",
    "        selected_neurons = sorted_idx[cum_sums <= total_mass * percentage]\n",
    "        neuron_orderings.extend(selected_neurons)\n",
    "\n",
    "    # Remove duplicates while preserving order\n",
    "    neuron_ordering = list(dict.fromkeys(neuron_orderings))\n",
    "\n",
    "    return np.array(neuron_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 23,\n",
       " 25,\n",
       " 26,\n",
       " 26,\n",
       " 29,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 33,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 37,\n",
       " 39,\n",
       " 41,\n",
       " 41,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 46,\n",
       " 46,\n",
       " 47,\n",
       " 50,\n",
       " 50,\n",
       " 51,\n",
       " 53,\n",
       " 54,\n",
       " 56,\n",
       " 56,\n",
       " 58,\n",
       " 60,\n",
       " 63,\n",
       " 63,\n",
       " 65,\n",
       " 67,\n",
       " 70,\n",
       " 72,\n",
       " 77,\n",
       " 83,\n",
       " 89,\n",
       " 100,\n",
       " 119,\n",
       " 189,\n",
       " 346,\n",
       " 555,\n",
       " 832,\n",
       " 1167,\n",
       " 1457,\n",
       " 1686,\n",
       " 1856,\n",
       " 1965,\n",
       " 2018,\n",
       " 2039,\n",
       " 2048,\n",
       " 2048]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ordering)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttsxai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
